{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Stylegan2-ada Custom Training.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPI5E5y0pujD"
      },
      "source": [
        "\n",
        "StyleGan2-ADA \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktqaMJUZuOl7"
      },
      "source": [
        "We are implementing Style GAN to generate multiple views of objects to be fed to DIB-R"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YcUMPQp6ipP"
      },
      "source": [
        "## Installing StyleGAN2-ADA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKYAU7Wub3WW"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19_1uXab3gND"
      },
      "source": [
        "Mounting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxxYlEKI9Gis"
      },
      "source": [
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "\n",
        "content_path = Path('/').absolute() / 'content'\n",
        "drive_path = content_path / 'drive'\n",
        "drive.mount(str(drive_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epV6TDzAjox1"
      },
      "source": [
        "We are using google drive to load and store images into our Google Colab Virtual Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HX77jscX2zV"
      },
      "source": [
        "stylegan2_repo_url  = 'https://github.com/dvschultz/stylegan2-ada' # or https://github.com/NVlabs/stylegan2-ada\n",
        "project_path        = drive_path / 'MyDrive' / 'StyleGAN2-ADA'\n",
        "stylegan2_repo_path = project_path / 'stylegan2-ada'\n",
        "\n",
        "# Create project folder if inexistant\n",
        "if not project_path.is_dir():\n",
        "    %mkdir \"{project_path}\"\n",
        "%cd \"{project_path}\"\n",
        "\n",
        "for dir in ['in', 'out', 'datasets', 'training']:\n",
        "    if not (project_path / dir).is_dir():\n",
        "        %mkdir {dir}\n",
        "if not (project_path / 'datasets' / 'source').is_dir():\n",
        "    %mkdir \"{project_path / 'datasets' / 'source'}\"\n",
        "\n",
        "# Download StyleGAN2-ada to train\n",
        "!git config --global user.name \"ArthurFDLR\"\n",
        "!git config --global user.email \"arthfind@gmail.com\"\n",
        "if stylegan2_repo_path.is_dir():\n",
        "    !git -C \"{stylegan2_repo_path}\" fetch origin\n",
        "    !git -C \"{stylegan2_repo_path}\" checkout origin/main -- *.py\n",
        "else:\n",
        "    print(\"Install StyleGAN2-ADA\")\n",
        "    !git clone {stylegan2_repo_url}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ti11YiPAiQpb"
      },
      "source": [
        "## We train the model using our car dataset and also allow try out the pre trained models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioqYi9NzkUfG"
      },
      "source": [
        "Loading the dataset and training the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlV5HIEqiZvu"
      },
      "source": [
        "dataset_name = '1'\n",
        "datasets_source_path = project_path / 'datasets' / 'source' / (dataset_name + '.zip')\n",
        "if datasets_source_path.is_dir():\n",
        "    print(\"Dataset ready for import.\")\n",
        "else:\n",
        "    print('Upload your images dataset as {}'.format(datasets_source_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-y1-tvr5617d"
      },
      "source": [
        "Unzip the dataset into our environment"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip -u \"/content/drive/MyDrive/StyleGAN2-ADA/datasets/source/1.zip\" -d \"/content/drive/MyDrive/StyleGAN2-ADA/datasets/source/\""
      ],
      "metadata": {
        "id": "xV1-SgyA0trI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQZGo4g5y7rh"
      },
      "source": [
        "local_dataset_path = content_path / 'dataset'\n",
        "if not local_dataset_path.is_dir():\n",
        "    print(\"Importing dataset...\")\n",
        "    %mkdir \"{local_dataset_path}\"\n",
        "    %cp -a \"{project_path / 'datasets' / 'source' / (dataset_name + '.zip')}\" \"{local_dataset_path}\"\n",
        "    print(\"Zip file succesfuly imported\")\n",
        "else:\n",
        "    print('Zip file allready imported')\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile(str(local_dataset_path / (dataset_name + '.zip')), 'r') as zip_ref:\n",
        "    zip_ref.extractall(str(local_dataset_path))\n",
        "print('Extraction completed')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeS9tDvt61VG"
      },
      "source": [
        "### Convert dataset to .tfrecords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Q58MJbckLUc"
      },
      "source": [
        "We need to convert our image dataset to tfr format as StyleGAN2-ADA is built to read tfrread format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjH8kBDo3kFP"
      },
      "source": [
        "local_images_path = local_dataset_path/ 'images'\n",
        "local_dataset_path /= 'tfr'\n",
        "print(local_images_path)\n",
        "\n",
        "if (local_dataset_path).is_dir():\n",
        "    print('\\N{Heavy Exclamation Mark Symbol} Dataset already created \\N{Heavy Exclamation Mark Symbol}')\n",
        "    print('Delete current dataset folder ({}) to regenerate tfrecords.'.format(local_dataset_path))\n",
        "else:\n",
        "    %mkdir \"{local_dataset_path}\"\n",
        "    !python \"{stylegan2_repo_path / 'dataset_tool.py'}\" create_from_images \\\n",
        "        \"{local_dataset_path}\" \"{local_images_path}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DvTupHzP2s_"
      },
      "source": [
        "We allow \n",
        "\n",
        "*   *mirror:* Should the images be mirrored vertically?\n",
        "*   *mirrory:* Should the images be mirrored horizontally?\n",
        "*   *snap:* How often should the model generate image samples and a network pickle (.pkl file)?\n",
        "*   *resume:* Network pickle to resume training from?\n",
        "\n",
        "To see all the options, run the following ```help``` cell.\n",
        "\n",
        "Please note that Google Colab Pro gives access to V100 GPUs, which drastically decreases (~3x) processing time over P100 GPUs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fxu7CA0Qb1Yd"
      },
      "source": [
        "!python \"{stylegan2_repo_path / 'train.py'}\" --help"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOftFoyiDU3s"
      },
      "source": [
        "training_path = project_path / 'training' / dataset_name\n",
        "if not training_path.is_dir():\n",
        "    %mkdir \"{training_path}\"\n",
        "\n",
        "#how often should the model generate samples \n",
        "snapshot_count = 2\n",
        "#the images mirrored left to right\n",
        "mirrored = True\n",
        "#the images mirrored top to bottom\n",
        "mirroredY = False\n",
        "#metrics\n",
        "metric_list = None\n",
        "#augments\n",
        "augs = 'bgc'\n",
        "\n",
        "resume_from = 'ffhq1024'\n",
        "!python \"{stylegan2_repo_path / 'train.py'}\" --outdir=\"{training_path}\" \\\n",
        "    --data=\"{local_dataset_path}\" --resume=\"{resume_from}\" \\\n",
        "    --snap={snapshot_count} --augpipe={augs} \\\n",
        "    --mirror={mirrored} --mirrory={mirroredY} \\\n",
        "    --metrics={metric_list} #--dry-run"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0A9ZNtferpk"
      },
      "source": [
        "## Generating images from pre-trained model\n",
        "\n",
        "\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnlrb9QzgaGp"
      },
      "source": [
        "%pip install opensimplex\n",
        "!python \"{stylegan2_repo_path / 'generate.py'}\" generate-images --help "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQqYjeRsfYD2"
      },
      "source": [
        "from numpy import random\n",
        "seed_init = random.randint(10000)\n",
        "nbr_images = 6\n",
        "\n",
        "generation_from = 'http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-car-config-e.pkl'\n",
        "\n",
        "!python \"{stylegan2_repo_path / 'generate.py'}\" generate-images \\\n",
        "    --outdir=\"{project_path / 'out'}\" --trunc=0.7 \\\n",
        "    --seeds={seed_init}-{seed_init+nbr_images-1} --create-grid \\\n",
        "    --network={generation_from}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yG1UyHXXqsO"
      },
      "source": [
        "Generating video frames of our object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veceGR6QYA93"
      },
      "source": [
        "%pip install opensimplex\n",
        "!python \"{stylegan2_repo_path / 'generate.py'}\" generate-latent-walk --help "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjsN05ksZYZ7"
      },
      "source": [
        "from numpy import random\n",
        "walk_types = ['line', 'sphere', 'noiseloop', 'circularloop']\n",
        "latent_walk_path = project_path / 'out' / 'latent_walk'\n",
        "if not latent_walk_path.is_dir():\n",
        "    %mkdir \"{latent_walk_path}\"\n",
        "\n",
        "explored_network = 'http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-car-config-e.pkl'\n",
        "\n",
        "seeds = [random.randint(10000) for i in range(10)]\n",
        "print(','.join(map(str, seeds)))\n",
        "print(\"Base seeds:\", seeds)\n",
        "!python \"{stylegan2_repo_path / 'generate.py'}\" generate-latent-walk --network=\"{explored_network}\" \\\n",
        "    --outdir=\"{latent_walk_path}\" --trunc=0.7 --walk-type=\"{walk_types[2]}\" \\\n",
        "    --seeds={','.join(map(str, seeds))} --frames {len(seeds)*20}"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}